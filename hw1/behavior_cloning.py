# Implement behavior cloning 


import tensorflow as tf 
import pickle
import numpy as np
import tf_util
import argparse
import load_policy
import gym
from sklearn.cross_validation import train_test_split
from sklearn.utils import shuffle


# Parameters

learning_rate = 0.001
num_epoch = 100
batch_size = 128

# Network Parameters

num_hid_1 = 128
num_hid_2 = 128


#Load training data from expert demonstrations generated by run_expert.py
def load_expert_data (filename):
	with open (filename, 'rb') as f:
		data = pickle.loads(f.read())
	return data

def data_preprocessing(x, y):

	x, y = shuffle(x, y, random_state=0)
	x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)
	y_train = y_train.reshape(y_train.shape[0], y_train.shape[2])
	y_test = y_test.reshape(y_test.shape[0], y_test.shape[2])

	return x_train, x_test, y_train, y_test

def next_batch(batch_size, x, y):

	indices = np.random.randint(low = 0, high = len(x), size = batch_size)
	input_batch = x[indices]
	label_batch = y[indices]

	return input_batch, label_batch

def network_model(num_obs, num_act):

	x = tf.placeholder(tf.float32, shape = [None, num_obs], name = 'x')
	y = tf.placeholder(tf.float32, shape = [None, num_act], name = 'y')
	layer_1 = tf.layers.dense(x, num_hid_1, activation = tf.nn.relu, use_bias=True)
	layer_2 = tf.layers.dense(layer_1, num_hid_2, activation = tf.nn.relu, use_bias = True)
	output = tf.layers.dense(layer_2, num_act, activation = None, use_bias = True)

	return output, x, y

def train_network(output, y):
	loss = tf.losses.mean_squared_error(output, y)
	train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)

	return loss, train_op



def main():
	parser = argparse.ArgumentParser();
	parser.add_argument('expert_policy_file', type=str)
	parser.add_argument('envname', type=str)
	parser.add_argument('--render', action='store_true')
	parser.add_argument("--max_timesteps", type=int)
	parser.add_argument('--num_rollouts', type=int, default=20,
                      help='Number of expert roll outs')
	args = parser.parse_args()

	task = args.envname
	dataset = 'expert_data/' + args.envname + '_' + str(args.num_rollouts) + '_data.pkl'


    #Load training data
	data = load_expert_data(dataset)
	observations = np.array(data['observations'])
	actions = np.array(data['actions'])
	num_obs = observations.shape[1]
	num_act = actions.shape[2]

	obs_train, obs_test, act_train, act_test = data_preprocessing(observations, actions)

	output, x, y = network_model(num_obs, num_act)

	lossfunction, train_op = train_network(output, y)

	tf.add_to_collection('pred_network', output)

	mean_reward = []
	std_reward = []


		# Train
	init = tf.global_variables_initializer()
		#model_path = './bc_policy/' + task + '_' + str(args.num_rollouts) + '_bc'
		#builder = tf.saved_model.builder.SavedModelBuilder(model_path)
	with tf.Session() as sess:
		sess.run(init)

		for epoch in range(num_epoch + 1):

			num_batch = int(len(obs_train) / batch_size)

			for num in range(num_batch):

				obs_train_batch, act_train_batch = next_batch(batch_size, obs_train, act_train)

				sess.run(train_op, feed_dict = {x: obs_train_batch, y: act_train_batch})

			if epoch % 10 == 0:

				loss = sess.run(lossfunction, feed_dict = {x: obs_train, y: act_train})

				print("Number of Epoch: %d, Training Loss = %.08f "%(epoch, loss))

				test_output = sess.run(output, feed_dict = {x: obs_test})

				testloss = np.mean((test_output - act_test)**2)

				print ("Testing loss = %.08f" % testloss)

				env = gym.make(args.envname)
				max_steps = args.max_timesteps or env.spec.timestep_limit

				returns = []
				observations = []
				actions = []
				for i in range(args.num_rollouts):
					print('iter', i)
					obs = env.reset()
					done = False
					totalr = 0.
					steps = 0
					while not done: 

						pre_action = sess.run(output, feed_dict = {x:obs[None,:]})
						observations.append(obs)
						actions.append(pre_action)
						obs, r, done, _ = env.step(pre_action)
						totalr += r
						steps += 1
						if args.render:
							env.render()
						#if steps % 100 == 0: print("%i/%i"%(steps, max_steps))
						if steps >= max_steps:
							break
					returns.append(totalr)

				print('returns', returns)
				print('mean return', np.mean(returns))
				print('std of return', np.std(returns))
				mean_reward.append(np.mean(returns))
				std_reward.append(np.std(returns))

			#builder.add_meta_graph_and_variables(sess, ['Training'])
			#builder.save
	BC_result = {'mean_reward': np.array(mean_reward),
					 'std_reward': np.array(std_reward)}


	outfilename = './' + args.envname + '_' + str(args.num_rollouts) + '_bc_data.pkl'

	with open((outfilename), 'wb') as f:
		pickle.dump(BC_result, f, pickle.HIGHEST_PROTOCOL)





if __name__ == '__main__':
    main()

